#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import json
import logging
import datetime
import requests
from dotenv import load_dotenv

# Optional OpenAI integration
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("ai_vulnerability_checker.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("AIVulnerabilityChecker")

class AIVulnerabilityChecker:
    """
    AI-powered vulnerability analyzer that can use either a specialized security API
    or a general-purpose AI like OpenAI to detect security vulnerabilities
    """
    
    def __init__(self, api_key=None, service_url=None):
        # Load environment variables
        load_dotenv()
        
        # Set API key
        self.api_key = api_key or os.environ.get("AI_SECURITY_API_KEY")
        # Set service URL
        self.service_url = service_url or os.environ.get(
            "AI_SECURITY_SERVICE_URL", 
            "https://api.ai-security-analysis.com/v1/analyze"
        )
        
        # For OpenAI
        self.openai_api_key = os.environ.get("OPENAI_API_KEY")
        self.openai_model = os.environ.get("OPENAI_MODEL", "gpt-4-turbo")
        
        # Check if we have necessary credentials
        if not self.api_key and not self.openai_api_key:
            logger.warning("No API keys provided. Either AI_SECURITY_API_KEY or OPENAI_API_KEY must be set.")
    
    def analyze_vulnerabilities(self, scan_data):
        """
        Analyze scan data for vulnerabilities using AI
        
        Args:
            scan_data (dict): Target and scan result data
            
        Returns:
            dict: AI analysis results
        """
        # Try using security API first
        if self.api_key:
            try:
                return self._analyze_with_security_api(scan_data)
            except Exception as e:
                logger.error(f"Error using security API: {str(e)}")
                # Fall back to OpenAI if available
                if OPENAI_AVAILABLE and self.openai_api_key:
                    logger.info("Falling back to OpenAI for vulnerability analysis")
                    return self._analyze_with_openai(scan_data)
                else:
                    raise
        # Use OpenAI if available and configured
        elif OPENAI_AVAILABLE and self.openai_api_key:
            return self._analyze_with_openai(scan_data)
        else:
            raise ValueError("No API keys configured. Set either AI_SECURITY_API_KEY or OPENAI_API_KEY")
    
    def _analyze_with_security_api(self, scan_data):
        """Use specialized security AI API"""
        logger.info(f"Sending data to security AI service: {self.service_url}")
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        
        response = requests.post(
            self.service_url,
            headers=headers,
            json=scan_data,
            timeout=60
        )
        
        if response.status_code != 200:
            raise Exception(f"API returned error: {response.status_code} - {response.text}")
        
        return response.json()
    
    def _analyze_with_openai(self, scan_data):
        """Use OpenAI for vulnerability analysis"""
        if not OPENAI_AVAILABLE:
            raise ImportError("OpenAI package is not installed. Install with 'pip install openai'")
        
        if not self.openai_api_key:
            raise ValueError("OpenAI API key not provided")
        
        logger.info(f"Using OpenAI ({self.openai_model}) for vulnerability analysis")
        
        # Configure OpenAI
        openai.api_key = self.openai_api_key
        
        # Prepare a simplified version of scan data to stay within token limits
        simplified_data = self._simplify_scan_data(scan_data)
        
        # Prepare the prompt
        prompt = self._prepare_openai_prompt(simplified_data)
        
        # Call OpenAI API
        try:
            completion = openai.ChatCompletion.create(
                model=self.openai_model,
                messages=[
                    {"role": "system", "content": "You are a cybersecurity expert specialized in vulnerability assessment."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2, # Low temperature for more focused results
                max_tokens=2000
            )
            
            # Process the response
            ai_response = completion.choices[0].message["content"].strip()
            
            # Parse the JSON response
            try:
                # Check if the response is wrapped in ```json``` blocks
                if "```json" in ai_response:
                    json_part = ai_response.split("```json")[1].split("```")[0].strip()
                    result = json.loads(json_part)
                else:
                    # Try to parse the whole response as JSON
                    result = json.loads(ai_response)
            except json.JSONDecodeError:
                logger.warning("Failed to parse OpenAI response as JSON. Using text format.")
                # Create a structured response from the text
                result = {
                    "model_version": self.openai_model,
                    "timestamp": datetime.datetime.now().isoformat(),
                    "insights": [
                        {
                            "title": "AI Security Analysis",
                            "description": ai_response,
                            "confidence": "Medium"
                        }
                    ],
                    "detected_vulnerabilities": [],
                    "recommendations": []
                }
            
            return result
            
        except Exception as e:
            logger.error(f"Error calling OpenAI API: {str(e)}")
            raise
    
    def _simplify_scan_data(self, scan_data):
        """Simplify scan data to reduce token count for OpenAI"""
        # Create a copy to avoid modifying the original
        simplified = {}
        
        # Include essential information
        simplified["target"] = scan_data.get("target")
        simplified["timestamp"] = scan_data.get("timestamp")
        
        # Simplify scan results
        simplified["scan_results"] = {}
        
        # Network findings - focus on open ports and services
        if "network" in scan_data.get("scan_results", {}):
            network_data = scan_data["scan_results"]["network"]
            simplified["scan_results"]["network"] = {
                "open_ports_summary": []
            }
            
            # Extract open ports and services
            if "port_scan" in network_data:
                for host, host_data in network_data["port_scan"].items():
                    if "ports" in host_data:
                        for proto, ports in host_data["ports"].items():
                            for port, port_info in ports.items():
                                if port_info["state"] == "open":
                                    simplified["scan_results"]["network"]["open_ports_summary"].append({
                                        "host": host,
                                        "port": port,
                                        "protocol": proto,
                                        "service": port_info.get("service", "unknown")
                                    })
        
        # Web findings - include vulnerability flags and headers
        if "web" in scan_data.get("scan_results", {}):
            web_data = scan_data["scan_results"]["web"]
            simplified["scan_results"]["web"] = {}
            
            # Include vulnerability flags
            if "xss" in web_data:
                simplified["scan_results"]["web"]["xss_vulnerable"] = web_data["xss"].get("vulnerable", False)
                
            if "sql_injection" in web_data:
                simplified["scan_results"]["web"]["sql_injection_vulnerable"] = web_data["sql_injection"].get("vulnerable", False)
                
            if "security_headers" in web_data:
                simplified["scan_results"]["web"]["missing_security_headers"] = web_data["security_headers"].get("missing_headers", [])
        
        # OSINT findings - include data breach info and exposed emails
        if "osint" in scan_data.get("scan_results", {}):
            osint_data = scan_data["scan_results"]["osint"]
            simplified["scan_results"]["osint"] = {}
            
            if "data_breaches" in osint_data and "breaches" in osint_data["data_breaches"]:
                simplified["scan_results"]["osint"]["breach_count"] = len(osint_data["data_breaches"]["breaches"])
                
            if "email_harvesting" in osint_data and "emails" in osint_data["email_harvesting"]:
                simplified["scan_results"]["osint"]["exposed_email_count"] = len(osint_data["email_harvesting"]["emails"])
        
        return simplified
    
    def _prepare_openai_prompt(self, scan_data):
        """Prepare a detailed prompt for OpenAI"""
        prompt = f"""
I need you to analyze security scan results for a target and identify potential vulnerabilities and provide security recommendations.

Here is the scan data in JSON format:
```
{json.dumps(scan_data, indent=2)}
```

Please analyze this data and provide a detailed security assessment. Your response should be in JSON format with the following structure:

```json
{{
  "model_version": "Your model identifier",
  "timestamp": "ISO format timestamp",
  "detected_vulnerabilities": [
    {{
      "type": "vulnerability_type",
      "name": "Vulnerability Name",
      "description": "Detailed description of the vulnerability",
      "severity": "High/Medium/Low",
      "cwe": "CWE-XXX if applicable",
      "affected_endpoints": {{
        "details": "Information about where the vulnerability was found"
      }},
      "confidence": "High/Medium/Low",
      "remediation": {{
        "description": "How to fix the vulnerability",
        "steps": [
          "Step 1",
          "Step 2"
        ]
      }}
    }}
  ],
  "insights": [
    {{
      "title": "Security Insight Title",
      "description": "Detailed explanation of the security insight",
      "confidence": "High/Medium/Low",
      "impact": "Potential impact of this issue"
    }}
  ],
  "recommendations": [
    {{
      "issue": "Security Issue",
      "recommendation": "Recommendation text",
      "priority": "high/medium/low",
      "implementation": [
        "Implementation step 1",
        "Implementation step 2"
      ],
      "references": [
        "URL or reference 1",
        "URL or reference 2"
      ]
    }}
  ]
}}
```

Focus on identifying:
1. Common web vulnerabilities like XSS, SQL injection, CSRF, etc.
2. Security misconfigurations based on open ports and services
3. Potential risks from exposed information in OSINT findings
4. Insights that might not be explicit in the scan data but can be inferred

Be thorough but accurate. Only report vulnerabilities if there's evidence to support them in the scan data. For each vulnerability, provide practical remediation steps.

Your response must be valid JSON.
"""
        return prompt

def main():
    """Command line interface for the AI vulnerability checker"""
    import argparse
    import sys
    
    parser = argparse.ArgumentParser(description="AI Vulnerability Checker")
    parser.add_argument("--input", "-i", required=True, help="Input JSON file with scan data")
    parser.add_argument("--output", "-o", help="Output JSON file for results", default="ai_vulnerability_results.json")
    parser.add_argument("--api-key", help="API key for AI service (overrides environment variable)")
    parser.add_argument("--service-url", help="URL for AI service (overrides environment variable)")
    parser.add_argument("--openai", action="store_true", help="Force using OpenAI API")
    args = parser.parse_args()
    
    try:
        # Load scan data
        with open(args.input, 'r') as f:
            scan_data = json.load(f)
        
        # Initialize AI checker
        ai_checker = AIVulnerabilityChecker(api_key=args.api_key, service_url=args.service_url)
        
        # Analyze vulnerabilities
        if args.openai:
            logger.info("Forcing OpenAI analysis")
            results = ai_checker._analyze_with_openai(scan_data)
        else:
            results = ai_checker.analyze_vulnerabilities(scan_data)
        
        # Save results
        with open(args.output, 'w') as f:
            json.dump(results, f, indent=4)
            
        print(f"Analysis complete. Results saved to {args.output}")
        
    except Exception as e:
        print(f"Error: {str(e)}")
        logger.error(f"Error in main execution: {str(e)}", exc_info=True)
        return 1
        
    return 0

if __name__ == "__main__":
    sys.exit(main()) 